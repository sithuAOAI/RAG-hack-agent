{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ACS Index and Azure SQL Database for Avatar Demo\n",
    "Use this notebook to create an Azure Cognitive Search Index and an Azure SQL Database and populate demo content for the Avatar outdoor shop application.  \n",
    "\n",
    "Ensure that you have the the Microsoft ODBC driver for SQL Server installed. Here are the instructions for Linux based systems:  \n",
    "https://learn.microsoft.com/en-us/sql/connect/odbc/linux-mac/installing-the-microsoft-odbc-driver-for-sql-server?view=sql-server-ver16&tabs=ubuntu18-install%2Calpine17-install%2Cdebian8-install%2Credhat7-13-install%2Crhel7-offline#18\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1700038369590
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-search-documents==11.4.0b6\n",
      "  Using cached azure_search_documents-11.4.0b6-py3-none-any.whl (306 kB)\n",
      "Collecting openai==0.28.1\n",
      "  Using cached openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "Collecting tenacity\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Collecting pyodbc\n",
      "  Downloading pyodbc-5.1.0-cp310-cp310-macosx_11_0_arm64.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting azure-common~=1.1\n",
      "  Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Collecting azure-core<2.0.0,>=1.24.0\n",
      "  Downloading azure_core-1.31.0-py3-none-any.whl (197 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.4/197.4 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting isodate>=0.6.0\n",
      "  Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.10.5-cp310-cp310-macosx_11_0_arm64.whl (389 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.1/389.1 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests>=2.20\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/sithukaungset/RAG-hack-agent/raghack/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0b6) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/sithukaungset/RAG-hack-agent/raghack/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.24.0->azure-search-documents==11.4.0b6) (4.12.2)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-macosx_11_0_arm64.whl (120 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.11.1-cp310-cp310-macosx_11_0_arm64.whl (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-macosx_11_0_arm64.whl (52 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.1.0-cp310-cp310-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: azure-common, urllib3, tqdm, tenacity, pyodbc, multidict, isodate, idna, frozenlist, charset-normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, yarl, requests, aiosignal, azure-core, aiohttp, openai, azure-search-documents\n",
      "Successfully installed aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 async-timeout-4.0.3 attrs-24.2.0 azure-common-1.1.28 azure-core-1.31.0 azure-search-documents-11.4.0b6 certifi-2024.8.30 charset-normalizer-3.3.2 frozenlist-1.4.1 idna-3.10 isodate-0.6.1 multidict-6.1.0 openai-0.28.1 pyodbc-5.1.0 requests-2.32.3 tenacity-9.0.0 tqdm-4.66.5 urllib3-2.2.3 yarl-1.11.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the '/Users/sithukaungset/RAG-hack-agent/raghack/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the required libraries\n",
    "%pip install azure-search-documents==11.4.0b6 openai==0.28.1 tenacity pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1700038372029
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json  \n",
    "import pandas as pd\n",
    "\n",
    "import pyodbc\n",
    "import requests\n",
    "import inspect\n",
    "\n",
    "import openai  \n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "from azure.search.documents.models import Vector  \n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchIndex,  \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SimpleField,  \n",
    "    SearchableField,  \n",
    "    SearchIndex,  \n",
    "    SemanticConfiguration,  \n",
    "    PrioritizedFields,  \n",
    "    SemanticField,  \n",
    "    SearchField,  \n",
    "    SemanticSettings,  \n",
    "    VectorSearch,  \n",
    "    VectorSearchAlgorithmConfiguration,  \n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "You need to have the following settings for your Azure resources defined in the `local.settings.json` file in the __api__ subfolder to populate the demo content for the outdoor app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1700038375485
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Load JSON file\n",
    "with open('../api/local.settings.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Azure Cognitive Search\n",
    "service_endpoint = data[\"Values\"][\"AZURE_SEARCH_ENDPOINT\"]\n",
    "key = data[\"Values\"][\"AZURE_SEARCH_API_KEY\"]\n",
    "index_name = data[\"Values\"][\"AZURE_SEARCH_INDEX\"]\n",
    "\n",
    "# Blob SAS URL for Azure Storage Account\n",
    "blob_sas_url = data[\"Values\"][\"BLOB_SAS_URL\"]\n",
    "\n",
    "# Azure OpenAI\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = data[\"Values\"][\"AZURE_OPENAI_API_KEY\"]\n",
    "openai.api_base = data[\"Values\"][\"AZURE_OPENAI_ENDPOINT\"]\n",
    "openai.api_version = data[\"Values\"][\"AZURE_OPENAI_API_VERSION\"]\n",
    "AOAI_embeddings_deployment = data[\"Values\"][\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"]\n",
    "\n",
    "# Azure SQL Database\n",
    "sql_db_server = data[\"Values\"][\"SQL_DB_SERVER\"]\n",
    "sql_db_user = data[\"Values\"][\"SQL_DB_USER\"]\n",
    "sql_db_password = data[\"Values\"][\"SQL_DB_PASSWORD\"]\n",
    "sql_db_name = data[\"Values\"][\"SQL_DB_NAME\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Cognitive Search Index\n",
    "First, we create a new Index with demo data to the Cognitive Search service that you have deployed manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gather": {
     "logged": 1699873170121
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>name</th>\n",
       "      <th>tagline</th>\n",
       "      <th>description</th>\n",
       "      <th>original_price</th>\n",
       "      <th>special_offer</th>\n",
       "      <th>product_image_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>Skincare</td>\n",
       "      <td>VT Reedle Shot</td>\n",
       "      <td>A beauty device for your skin. Tackles both po...</td>\n",
       "      <td>Ingredients in the form of microneedles smalle...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>24.59</td>\n",
       "      <td>vt-reedle-shot.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>Skincare</td>\n",
       "      <td>Anua Cleansing oil</td>\n",
       "      <td>Deep Cleanse, Gentle Care: Effortlessly Dissol...</td>\n",
       "      <td>Why We Love It Anua Heartleaf Pore Control Cle...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.90</td>\n",
       "      <td>anua-pore-cleansing.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>Skincare</td>\n",
       "      <td>Numbuzin vitamin concentrated serum</td>\n",
       "      <td>Reveal Radiant Skin: Powerful Brightening and ...</td>\n",
       "      <td>Why We Love It Thoroughly removes any blemish ...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>29.90</td>\n",
       "      <td>numbuzin-vitamin-serum.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>Skincare</td>\n",
       "      <td>Dr.G Clear Sooothing Cream</td>\n",
       "      <td>Dr.G ritual to naturally glowing skin</td>\n",
       "      <td>Korea’s No.1 Soothing Cream A lightweight, fas...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>27.52</td>\n",
       "      <td>drG-cream.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>Skincare</td>\n",
       "      <td>ilso Super Melting Sebum Softener</td>\n",
       "      <td>Wellknown for blackheads care</td>\n",
       "      <td>Why We Love It Introducing the Sebum Softener,...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>ilso-sebum-softener.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  category                                 name  \\\n",
       "0  1000  Skincare                       VT Reedle Shot   \n",
       "1  1001  Skincare                   Anua Cleansing oil   \n",
       "2  1002  Skincare  Numbuzin vitamin concentrated serum   \n",
       "3  1003  Skincare          Dr.G Clear Sooothing Cream    \n",
       "4  1004  Skincare    ilso Super Melting Sebum Softener   \n",
       "\n",
       "                                             tagline  \\\n",
       "0  A beauty device for your skin. Tackles both po...   \n",
       "1  Deep Cleanse, Gentle Care: Effortlessly Dissol...   \n",
       "2  Reveal Radiant Skin: Powerful Brightening and ...   \n",
       "3              Dr.G ritual to naturally glowing skin   \n",
       "4                      Wellknown for blackheads care   \n",
       "\n",
       "                                         description  original_price  \\\n",
       "0  Ingredients in the form of microneedles smalle...            32.0   \n",
       "1  Why We Love It Anua Heartleaf Pore Control Cle...            40.0   \n",
       "2  Why We Love It Thoroughly removes any blemish ...            46.0   \n",
       "3  Korea’s No.1 Soothing Cream A lightweight, fas...            42.0   \n",
       "4  Why We Love It Introducing the Sebum Softener,...            26.0   \n",
       "\n",
       "   special_offer          product_image_file  \n",
       "0          24.59          vt-reedle-shot.png  \n",
       "1          25.90     anua-pore-cleansing.png  \n",
       "2          29.90  numbuzin-vitamin-serum.jpg  \n",
       "3          27.52               drG-cream.jpg  \n",
       "4          23.00     ilso-sebum-softener.jpg  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "credential = AzureKeyCredential(key)\n",
    "\n",
    "df = pd.read_csv('../data/cosmetics.csv', dtype={'id': str})\n",
    "display(df.head())\n",
    "input_data = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "gather": {
     "logged": 1699873170374
    }
   },
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "def generate_embeddings(text):\n",
    "    response = openai.Embedding.create(\n",
    "        input=text, engine=AOAI_embeddings_deployment)\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "gather": {
     "logged": 1699873171802
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Generate embeddings for title and content fields\n",
    "for item in input_data:\n",
    "    tagline = item['tagline']\n",
    "    description = item['description']\n",
    "    tagline_embeddings = generate_embeddings(tagline)\n",
    "    description_embeddings = generate_embeddings(description)\n",
    "    item['tagline_vector'] = tagline_embeddings\n",
    "    item['description_vector'] = description_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "gather": {
     "logged": 1699873171984
    }
   },
   "outputs": [],
   "source": [
    "# Output embeddings to docVectors.json file\n",
    "with open(\"../data/cosmetic-catalog-vectors.json\", \"w\") as f:\n",
    "    json.dump(input_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gather": {
     "logged": 1699873172252
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index does not exist. No need to delete it.\n"
     ]
    }
   ],
   "source": [
    "# Delete ACS index if it exists\n",
    "index_client = SearchIndexClient(endpoint=service_endpoint, credential=credential)\n",
    "\n",
    "try:\n",
    "    if index_client.get_index(index_name):\n",
    "        print('Deleting existing index...')\n",
    "        index_client.delete_index(index_name)\n",
    "\n",
    "except:\n",
    "    print('Index does not exist. No need to delete it.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "gather": {
     "logged": 1699873172892
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cosmetics created\n"
     ]
    }
   ],
   "source": [
    "# Create a search index\n",
    "index_client = SearchIndexClient(endpoint=service_endpoint, credential=credential)\n",
    "\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"name\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"tagline\", type=SearchFieldDataType.String),\n",
    "    SearchableField(name=\"description\", type=SearchFieldDataType.String),\n",
    "    SimpleField(name=\"original_price\", type=SearchFieldDataType.Double),\n",
    "    SimpleField(name=\"special_offer\", type=SearchFieldDataType.Double),\n",
    "    SearchableField(name=\"category\", type=SearchFieldDataType.String, filterable=True),\n",
    "    SearchField(name=\"tagline_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
    "    SearchField(name=\"description_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
    "    SimpleField(name=\"product_image_file\", type=SearchFieldDataType.String),\n",
    "]\n",
    "\n",
    "vector_search = VectorSearch(\n",
    "    algorithm_configurations=[\n",
    "        VectorSearchAlgorithmConfiguration(\n",
    "            name=\"my-vector-config\",\n",
    "            kind=\"hnsw\",\n",
    "            hnsw_parameters={\n",
    "                \"m\": 4,\n",
    "                \"efConstruction\": 400,\n",
    "                \"efSearch\": 500,\n",
    "                \"metric\": \"cosine\"\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=PrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"tagline\"),\n",
    "        prioritized_keywords_fields=[SemanticField(field_name=\"category\")],\n",
    "        prioritized_content_fields=[SemanticField(field_name=\"description\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_settings = SemanticSettings(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,\n",
    "                    vector_search=vector_search, semantic_settings=semantic_settings)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "gather": {
     "logged": 1699873173454
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 19 documents\n"
     ]
    }
   ],
   "source": [
    "# Upload documents to the index\n",
    "with open(\"../data/cosmetic-catalog-vectors.json\", 'r') as file:  \n",
    "    documents = json.load(file)  \n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
    "result = search_client.upload_documents(documents)  \n",
    "print(f\"Uploaded {len(documents)} documents\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Perform Test Queries\n",
    "We are performing a few test queries against the Cognitive Search index. If successful, it should display outdoor product information and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "gather": {
     "logged": 1699873173581
    }
   },
   "outputs": [],
   "source": [
    "search_client = SearchClient(service_endpoint, index_name, credential=credential)  \n",
    "fields_of_interest = [\"id\", \"name\", \"tagline\", \"description\", \"original_price\", \"special_offer\", \"category\", \"product_image_file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "gather": {
     "logged": 1699873175487
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from matplotlib import pyplot as plt\n",
    "from io import BytesIO\n",
    "\n",
    "def display_image_from_blob(image_file):\n",
    "   \n",
    "  # Append the image name to the SAS URL\n",
    "  image_url = blob_sas_url.split(\"?\")[0] + f\"/{image_file}?\" + blob_sas_url.split(\"?\")[1]\n",
    "\n",
    "  # Get the image content\n",
    "  response = requests.get(image_url)\n",
    "\n",
    "  # Check if the request was successful\n",
    "  if response.status_code == 200:\n",
    "      # Open the image and display it\n",
    "      img = plt.imread(BytesIO(response.content))\n",
    "      plt.imshow(img)\n",
    "      plt.axis('off') # No axes for this plot\n",
    "      plt.show()\n",
    "  else:\n",
    "      print(f\"Failed to retrieve image. HTTP Status code: {response.status_code}\")\n",
    "\n",
    "def print_results(results):  \n",
    "  for result in results:  \n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Name: {result['name']}\")  \n",
    "    print(f\"Category: {result['category']}\")\n",
    "    print(f\"Tagline: {result['tagline']}\")\n",
    "    print(f\"Description: {result['description'][:50]}\")\n",
    "    print(f\"Original price: {result['original_price']}\")\n",
    "    print(f\"Special offer: {result['special_offer']}\")\n",
    "    print(f\"Image file: {result['product_image_file']}\\n\")\n",
    "    display_image_from_blob(result['product_image_file'])\n",
    "\n",
    "\n",
    "# Pure Vector Search with Filter\n",
    "query = \"cushion for beauty\"  \n",
    " \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector=generate_embeddings(query), top_k=3,  \n",
    "    vector_fields=\"description_vector\",\n",
    "    filter=\"category eq 'Beauty Cushions'\", \n",
    "    select= fields_of_interest\n",
    ")  \n",
    "  \n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure SQL Database\n",
    "Now we are creating a small Azure SQL Database with customer, products and order data using the SQL Server that you have deployed manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "gather": {
     "logged": 1699873175635
    }
   },
   "outputs": [],
   "source": [
    "# Connection Strings\n",
    "server_connection_string = \"Driver={ODBC Driver 18 for SQL Server};Server=tcp:teamgptsqlserver.database.windows.net,1433;Database=teamgptsql;Uid=teamaoai;Pwd=sithu27!;Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\"\n",
    "database_connection_string = server_connection_string + f\"Database={sql_db_name};\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "gather": {
     "logged": 1699873175773
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "customers = [\n",
    "    {\"name\": \"John Doe\", \"account_id\": 1000, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Jane Smith\", \"account_id\": 1001, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Alice Johnson\", \"account_id\": 1002, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Bob Wilson\", \"account_id\": 1003, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Charlie Brown\", \"account_id\": 1004, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Eve Adams\", \"account_id\": 1005, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Frank Castle\", \"account_id\": 1006, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Grace Lee\", \"account_id\": 1007, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Hannah Montan\", \"account_id\": 1008, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Ian Somerhalder\", \"account_id\": 1009, \"loyalty_points\" : random.randint(400, 800)},\n",
    "    {\"name\": \"Peter Mick\", \"account_id\": 1010, \"loyalty_points\" : random.randint(400, 800)},\n",
    "]\n",
    "\n",
    "products = [\n",
    "    {\"id\": 1000, \"name\": \"Elysian Voyager\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1001, \"name\": \"Terra Roamer\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1002, \"name\": \"Cardinal Pathfinder\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1003, \"name\": \"Slumber Drifter\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1004, \"name\": \"Blaze Adventurer\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1005, \"name\": \"BiteShield Pro\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1006, \"name\": \"Feast Frontier\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1007, \"name\": \"Summit Stride\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1008, \"name\": \"Rugged Ranger\",\"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1100, \"name\": \"Match Master\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1101, \"name\": \"Court Queen\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1102, \"name\": \"Junior Ace\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1103, \"name\": \"ServeMaster Pro\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1104, \"name\": \"Court Commander\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1105, \"name\": \"StringMaster Elite\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1106, \"name\": \"Court Conqueror\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1107, \"name\": \"AceMaster 3000\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1108, \"name\": \"Ace Attire\", \"stock\": random.randint(0,50)},\n",
    "    {\"id\": 1109, \"name\": \"Serve & Style\", \"stock\": random.randint(0,50)},\n",
    "]\n",
    "orders = [\n",
    "    {\"order_id\": 1000, \"product_id\": 1001, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1000},\n",
    "    {\"order_id\": 1001, \"product_id\": 1001, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1001},\n",
    "    {\"order_id\": 1002, \"product_id\": 1002, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1002},\n",
    "    {\"order_id\": 1003, \"product_id\": 1003, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1003},\n",
    "    {\"order_id\": 1004, \"product_id\": 1004, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1004},\n",
    "    {\"order_id\": 1005, \"product_id\": 1005, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1005},\n",
    "    {\"order_id\": 1006, \"product_id\": 1006, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1006},\n",
    "    {\"order_id\": 1007, \"product_id\": 1007, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1007},\n",
    "    {\"order_id\": 1008, \"product_id\": 1008, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1008},\n",
    "    {\"order_id\": 1010, \"product_id\": 1000, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1009},\n",
    "    {\"order_id\": 1012, \"product_id\": 1101, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1001},\n",
    "    {\"order_id\": 1013, \"product_id\": 1102, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1002},\n",
    "    {\"order_id\": 1014, \"product_id\": 1103, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1003},\n",
    "    {\"order_id\": 1015, \"product_id\": 1104, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1004},\n",
    "    {\"order_id\": 1016, \"product_id\": 1105, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1005},\n",
    "    {\"order_id\": 1017, \"product_id\": 1106, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1006},\n",
    "    {\"order_id\": 1018, \"product_id\": 1107, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1007},\n",
    "    {\"order_id\": 1019, \"product_id\": 1108, \"days_to_delivery\": random.randint(3,15), \"account_id\": 1008},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "gather": {
     "logged": 1699873175920
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to connect to the server/database. SQLSTATE: 01000, Message: [01000] [unixODBC][Driver Manager]Can't open lib 'ODBC Driver 18 for SQL Server' : file not found (0) (SQLDriverConnect)\n"
     ]
    }
   ],
   "source": [
    "# Test connection to the SQL Server\n",
    "\n",
    "try:\n",
    "    # Try to establish a connection\n",
    "    conn = pyodbc.connect(server_connection_string)\n",
    "    \n",
    "    # If connection is successful, print a message and close the connection\n",
    "    print(\"Connection to the server/database was successful!\")\n",
    "    conn.close()\n",
    "    \n",
    "except pyodbc.Error as ex:\n",
    "    # Catch any connection errors and print them\n",
    "    sqlstate = ex.args[0] if len(ex.args) > 0 else None\n",
    "    message = ex.args[1] if len(ex.args) > 1 else None\n",
    "    print(f\"Failed to connect to the server/database. SQLSTATE: {sqlstate}, Message: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "gather": {
     "logged": 1699873247080
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: Customers\n",
      "    name (varchar)\n",
      "    account_id (int)\n",
      "    loyalty_points (int)\n",
      "\n",
      "Table: Orders\n",
      "    order_id (int)\n",
      "    product_id (int)\n",
      "    days_to_delivery (int)\n",
      "    account_id (int)\n",
      "\n",
      "Table: Products\n",
      "    id (int)\n",
      "    name (varchar)\n",
      "    stock (int)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SET TO TRUE ONLY TO REBUILD DATABASE BASED ON ABOVE SAMPLE DATA\n",
    "rebuild_database = True\n",
    "\n",
    "if rebuild_database:\n",
    "\n",
    "    # Connect to the server without specifying a database\n",
    "    server_conn = pyodbc.connect(server_connection_string, autocommit=True)\n",
    "    server_cursor = server_conn.cursor()\n",
    "\n",
    "    # Drop the database if it exists\n",
    "    server_cursor.execute(f\"IF EXISTS(SELECT * FROM sys.databases WHERE name='{sql_db_name}') DROP DATABASE {sql_db_name}\")\n",
    "\n",
    "    # Recreate the database\n",
    "    server_cursor.execute(f\"CREATE DATABASE {sql_db_name}\")\n",
    "    server_cursor.close()\n",
    "    server_conn.close()\n",
    "\n",
    "    # Now, connect to the newly created database\n",
    "    conn = pyodbc.connect(database_connection_string)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Ensure you're using the existing database\n",
    "    cursor.execute(f\"USE {sql_db_name}\")\n",
    "\n",
    "    # Create tables and populate them\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE Customers (\n",
    "        name VARCHAR(255),\n",
    "        account_id INT PRIMARY KEY,\n",
    "        loyalty_points INT,\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    for customer in customers:\n",
    "        cursor.execute(\"INSERT INTO Customers VALUES (?, ?, ?)\", \n",
    "                    (customer[\"name\"], customer[\"account_id\"], customer[\"loyalty_points\"]))\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE Products (\n",
    "        id INT PRIMARY KEY,\n",
    "        name VARCHAR(255),\n",
    "        stock INT\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    for product in products:\n",
    "        cursor.execute(\"INSERT INTO Products VALUES (?, ?, ?)\", \n",
    "                    (product[\"id\"], product[\"name\"], product[\"stock\"]))\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE Orders (\n",
    "        order_id INT PRIMARY KEY,\n",
    "        product_id INT,\n",
    "        days_to_delivery INT,\n",
    "        account_id INT,\n",
    "        FOREIGN KEY(product_id) REFERENCES Products(id),\n",
    "        FOREIGN KEY(account_id) REFERENCES Customers(account_id)\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    for order in orders:\n",
    "        cursor.execute(\"INSERT INTO Orders VALUES (?, ?, ?, ?)\", \n",
    "                    (order[\"order_id\"], order[\"product_id\"], order[\"days_to_delivery\"], order[\"account_id\"]))\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "    #Verify database tables and columns\n",
    "    def fetch_schema_info():\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT t.TABLE_NAME, c.COLUMN_NAME, c.DATA_TYPE \n",
    "            FROM INFORMATION_SCHEMA.TABLES AS t\n",
    "            JOIN INFORMATION_SCHEMA.COLUMNS AS c ON t.TABLE_NAME = c.TABLE_NAME\n",
    "            WHERE t.TABLE_SCHEMA = 'dbo'  -- assuming you're using the default schema\n",
    "            ORDER BY t.TABLE_NAME, c.ORDINAL_POSITION\n",
    "        \"\"\")\n",
    "        \n",
    "        tables = {}\n",
    "        for row in cursor.fetchall():\n",
    "            table_name = row[0]\n",
    "            column_name = row[1]\n",
    "            data_type = row[2]\n",
    "            \n",
    "            if table_name not in tables:\n",
    "                tables[table_name] = []\n",
    "            \n",
    "            tables[table_name].append(f\"{column_name} ({data_type})\")\n",
    "        \n",
    "        return tables\n",
    "\n",
    "    schema_info = fetch_schema_info()\n",
    "\n",
    "    # Print the schema info in a user-friendly format\n",
    "    for table, columns in schema_info.items():\n",
    "        print(f\"Table: {table}\")\n",
    "        for col in columns:\n",
    "            print(f\"    {col}\")\n",
    "        print()\n",
    "\n",
    "    # Close connections\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
